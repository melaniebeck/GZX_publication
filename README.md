# human_machine_paper

|Fig Description			|		LateX label                 |
|---------------------------|-----------------------------------|
|GZ Express Schematic			|    fig: schematic             |
|volunteer probs                |  fig: volunteer training      |
|SWAP Fiducial model		|		fig: fiducial run      |
|SWAP vote distributions	|		fig: swap vote distributions      |
|SWAP; vary conf matrix		|	fig: confusionMatrixAnalysis      |
|SWAP; vary prior			|	    fig: priorAnalysis      |
| ROC curve                  |     fig: retirement thresholds      |
|SWAP disagrees with GZ2	|		fig: SWAP sucks      |
|GZX performance			|		fig: money      |
|Machine only performance	|	    fig: machine accuracy      |
|Machine classifies shit 	|	    fig: machine classified      |


## Needed Figures
1. Machine Learning Curve -- justify "learned" decision
2. Machine FAILS on what?
3. Machine training/learning performance


## Figures that need desparate tweaking
1. ~~The Horrible GZ Express "Schematic": this is all kinds of bad~~
2. ~~SWAP fiducial model: "GZExpress" = "SWAP"~~
3. ~~SWAP vote distributions: Need to verify these are even from the correct simulation~~
4. ~~SWAP FAILED: this whole thing is hideous~~
5. Machine only performance: X axis is incorrect -- those are dates; not days!
6. Show that the UNCLASSIFIED don't have a strong peak anywhere in probability space \\
    (i.e. changing the p_machine from 0.9 won't really help a lot)

## Why do you need a machine at all?
SHOW CUTS ON MORPHOLOGY PARAMETERS ALONE ARE NOT ENOUGH TO MATCH THE 
ACCURACY OF WHAT CAN BE ACHIEVED WITH A SIMPLE MACHINE????

Standard cuts that people make to classify shits: 
1. C-A plane
2. G-M20 plane
3. The old C = 2.5 cut to separate Bulge from Disk

Make these cuts on the machine-classified ONLY sample?
Make these cuts on non-SWAP classified stuff? -- yes, probably this? 

For each cut, what would be classified as "Feat" and "Not" (Disk-y, Bulge-y)
With what accuracy/completeness/purity??

## Why do we need citizen scientists at all? 
1. Machines need training data; the more complex, the more data!!!
2. Point back to how the machine can't classify everything -- Few models will have the necessary complexity to capture everything. You won't know a priori how well
your model will capture the data. Over time, it will become apparent what it can and can't handle. You can trade out for a different model, or you can let humans
take a look at what the machien struggles with as this could be an area ripe for discovery. 

